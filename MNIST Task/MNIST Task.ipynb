{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe5773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdea8c7",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653689b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakbari/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/nakbari/.cache/kagglehub/datasets/alexanderyyy/mnist-png/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alexanderyyy/mnist-png\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc8428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder_path = f'{path}/mnist_png/train';\n",
    "testing_folder_path = f'{path}/mnist_png/test';\n",
    "\n",
    "T = 200  # Total simulation time\n",
    "dt = 0.2  # Simulation time step\n",
    "nt = round(T / dt)  # Total simulation steps\n",
    "time = np.linspace(0, T, nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f180ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size:  10000\n",
      "Train size:  60000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std for MNIST\n",
    "])\n",
    "\n",
    "rf_data_test = []\n",
    "rf_data_train = []\n",
    "\n",
    "for digit in range(10):\n",
    "    digit_folder_path = os.path.join(testing_folder_path, str(digit))\n",
    "    files = sorted([os.path.join(digit_folder_path, f) for f in os.listdir(digit_folder_path)])\n",
    "    for file_path in files:\n",
    "        image = Image.open(file_path)\n",
    "        image = transform(image) \n",
    "        rf_data_test.append({'Value': image, 'Label': digit})\n",
    "\n",
    "    digit_folder_path = os.path.join(training_folder_path, str(digit))\n",
    "    files = sorted([os.path.join(digit_folder_path, f) for f in os.listdir(digit_folder_path)])\n",
    "    for file_path in files:\n",
    "        image = Image.open(file_path)\n",
    "        image = transform(image).squeeze(0)\n",
    "        rf_data_train.append({'Value': image, 'Label': digit})\n",
    "\n",
    "print(\"Test Size: \", len(rf_data_test))\n",
    "print(\"Train size: \", len(rf_data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d59a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3025a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_signals = []\n",
    "\n",
    "for i in range(10):\n",
    "    signal = np.zeros((nt, 10))\n",
    "    signal[:, i] = 1\n",
    "    output_signals.append(signal)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for j in range(10):\n",
    "    label = rf_data_train[11]['Label']\n",
    "    plt.plot(time, output_signals[label][:, j] + j, 'r', linewidth=2)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Signal + Offset')\n",
    "plt.title('Output Signal Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835af2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000, 1, 28, 28])\n",
      "torch.Size([10000])\n",
      "torch.Size([10, 1000, 10])\n"
     ]
    }
   ],
   "source": [
    "train_values = np.array([item['Value'] for item in rf_data_train])\n",
    "train_labels = np.array([item['Label'] for item in rf_data_train])\n",
    "\n",
    "test_values = np.array([item['Value'] for item in rf_data_test])\n",
    "test_labels = np.array([item['Label'] for item in rf_data_test])\n",
    "\n",
    "train_values_tensor = torch.tensor(train_values, dtype=torch.float32)  # Spike trains\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.int)  # Labels\n",
    "test_values_tensor = torch.tensor(test_values, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.int)\n",
    "\n",
    "output_signals_tensor = torch.stack([torch.tensor(signal, dtype=torch.float32) for signal in output_signals])\n",
    "\n",
    "\n",
    "print(train_values_tensor.shape)\n",
    "print(train_labels_tensor.shape)\n",
    "print(test_values_tensor.shape)\n",
    "print(test_labels_tensor.shape)\n",
    "print(output_signals_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7e1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "\n",
    "batch_size = 200\n",
    "train_dataloader = DataLoader(TensorDataset(train_values_tensor, train_labels_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(TensorDataset(test_values_tensor, test_labels_tensor), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd41c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values_tensor = train_values_tensor.to(device)\n",
    "train_labels_tensor = train_labels_tensor.to(device)\n",
    "output_signals_tensor = output_signals_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec05e45",
   "metadata": {},
   "source": [
    "## ML-SNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_output(s_e: torch.Tensor, s_i: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor) -> torch.Tensor:\n",
    "    cat = torch.cat([s_e, s_i], 1)\n",
    "    return F.linear(cat, weight, bias)\n",
    "\n",
    "@torch.jit.script\n",
    "def compute_derivatives(\n",
    "    V_e: torch.Tensor, n_e: torch.Tensor, s_e: torch.Tensor,\n",
    "    V_i: torch.Tensor, n_i: torch.Tensor, s_i: torch.Tensor,\n",
    "    I_e: torch.Tensor, I_i: torch.Tensor,\n",
    "    omega_ee: torch.Tensor, omega_ei: torch.Tensor, \n",
    "    omega_ie: torch.Tensor, omega_ii: torch.Tensor,\n",
    "    V1: float, V2: float, V3: float, V4: float,\n",
    "    T_max: float, V_t: float, K_p: float,\n",
    "    g_Ca: float, V_Ca: float, g_K: float, V_K: float, g_L: float, V_L: float,\n",
    "    phi: float, ar_e: float, ad_e: float, ar_i: float, ad_i: float,\n",
    "    gbar_e: float, gbar_i: float, E_ampa: float, E_gaba: float,\n",
    "    Cm: float\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    m_inf_e = 0.5 * (1 + torch.tanh((V_e - V1) / V2))\n",
    "    n_inf_e = 0.5 * (1 + torch.tanh((V_e - V3) / V4))\n",
    "    tau_n_e = 1.0 / torch.cosh((V_e - V3) / (2 * V4))\n",
    "    TM_e = T_max / (1 + torch.exp(-(V_e - V_t) / K_p))\n",
    "    \n",
    "    m_inf_i = 0.5 * (1 + torch.tanh((V_i - V1) / V2))\n",
    "    n_inf_i = 0.5 * (1 + torch.tanh((V_i - V3) / V4))\n",
    "    tau_n_i = 1.0 / torch.cosh((V_i - V3) / (2 * V4))\n",
    "    TM_i = T_max / (1 + torch.exp(-(V_i - V_t) / K_p))\n",
    "    \n",
    "    I_syn_e = (gbar_e * torch.mm(s_e, omega_ee.transpose(0,1)) * (V_e - E_ampa) +\n",
    "               gbar_i * torch.mm(s_i, omega_ei.transpose(0,1)) * (V_e - E_gaba))\n",
    "    I_syn_i = (gbar_e * torch.mm(s_e, omega_ie.transpose(0,1)) * (V_i - E_ampa) +\n",
    "               gbar_i * torch.mm(s_i, omega_ii.transpose(0,1)) * (V_i - E_gaba))\n",
    "    \n",
    "    dV_e = (I_e - g_L*(V_e - V_L) - g_K*n_e*(V_e - V_K) - g_Ca*m_inf_e*(V_e - V_Ca) - I_syn_e) / Cm\n",
    "    dn_e = phi*(n_inf_e - n_e) / tau_n_e\n",
    "    ds_e = ar_e * TM_e * (1.0 - s_e) - ad_e * s_e\n",
    "    \n",
    "    dV_i = (I_i - g_L*(V_i - V_L) - g_K*n_i*(V_i - V_K) - g_Ca*m_inf_i*(V_i - V_Ca) - I_syn_i) / Cm\n",
    "    dn_i = phi*(n_inf_i - n_i) / tau_n_i\n",
    "    ds_i = ar_i * TM_i * (1.0 - s_i) - ad_i * s_i\n",
    "    \n",
    "    return dV_e, dn_e, ds_e, dV_i, dn_i, ds_i\n",
    "\n",
    "@torch.jit.script\n",
    "def rk4_step(\n",
    "    V_e: torch.Tensor, n_e: torch.Tensor, s_e: torch.Tensor,\n",
    "    V_i: torch.Tensor, n_i: torch.Tensor, s_i: torch.Tensor,\n",
    "    I_e: torch.Tensor, I_i: torch.Tensor, dt: float,\n",
    "    omega_ee: torch.Tensor, omega_ei: torch.Tensor, \n",
    "    omega_ie: torch.Tensor, omega_ii: torch.Tensor,\n",
    "    V1: float, V2: float, V3: float, V4: float,\n",
    "    T_max: float, V_t: float, K_p: float,\n",
    "    g_Ca: float, V_Ca: float, g_K: float, V_K: float, g_L: float, V_L: float,\n",
    "    phi: float, ar_e: float, ad_e: float, ar_i: float, ad_i: float,\n",
    "    gbar_e: float, gbar_i: float, E_ampa: float, E_gaba: float,\n",
    "    Cm: float\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    k1 = compute_derivatives(V_e, n_e, s_e, V_i, n_i, s_i, I_e, I_i,\n",
    "                             omega_ee, omega_ei, omega_ie, omega_ii,\n",
    "                             V1, V2, V3, V4, T_max, V_t, K_p,\n",
    "                             g_Ca, V_Ca, g_K, V_K, g_L, V_L,\n",
    "                             phi, ar_e, ad_e, ar_i, ad_i,\n",
    "                             gbar_e, gbar_i, E_ampa, E_gaba, Cm)\n",
    "    V_e_k2 = V_e + 0.5 * dt * k1[0]\n",
    "    n_e_k2 = n_e + 0.5 * dt * k1[1]\n",
    "    s_e_k2 = s_e + 0.5 * dt * k1[2]\n",
    "    V_i_k2 = V_i + 0.5 * dt * k1[3]\n",
    "    n_i_k2 = n_i + 0.5 * dt * k1[4]\n",
    "    s_i_k2 = s_i + 0.5 * dt * k1[5]\n",
    "    k2 = compute_derivatives(V_e_k2, n_e_k2, s_e_k2, V_i_k2, n_i_k2, s_i_k2, I_e, I_i,\n",
    "                             omega_ee, omega_ei, omega_ie, omega_ii,\n",
    "                             V1, V2, V3, V4, T_max, V_t, K_p,\n",
    "                             g_Ca, V_Ca, g_K, V_K, g_L, V_L,\n",
    "                             phi, ar_e, ad_e, ar_i, ad_i,\n",
    "                             gbar_e, gbar_i, E_ampa, E_gaba, Cm)\n",
    "    V_e_k3 = V_e + 0.5 * dt * k2[0]\n",
    "    n_e_k3 = n_e + 0.5 * dt * k2[1]\n",
    "    s_e_k3 = s_e + 0.5 * dt * k2[2]\n",
    "    V_i_k3 = V_i + 0.5 * dt * k2[3]\n",
    "    n_i_k3 = n_i + 0.5 * dt * k2[4]\n",
    "    s_i_k3 = s_i + 0.5 * dt * k2[5]\n",
    "    k3 = compute_derivatives(V_e_k3, n_e_k3, s_e_k3, V_i_k3, n_i_k3, s_i_k3, I_e, I_i,\n",
    "                             omega_ee, omega_ei, omega_ie, omega_ii,\n",
    "                             V1, V2, V3, V4, T_max, V_t, K_p,\n",
    "                             g_Ca, V_Ca, g_K, V_K, g_L, V_L,\n",
    "                             phi, ar_e, ad_e, ar_i, ad_i,\n",
    "                             gbar_e, gbar_i, E_ampa, E_gaba, Cm)\n",
    "    V_e_k4 = V_e + dt * k3[0]\n",
    "    n_e_k4 = n_e + dt * k3[1]\n",
    "    s_e_k4 = s_e + dt * k3[2]\n",
    "    V_i_k4 = V_i + dt * k3[3]\n",
    "    n_i_k4 = n_i + dt * k3[4]\n",
    "    s_i_k4 = s_i + dt * k3[5]\n",
    "    k4 = compute_derivatives(V_e_k4, n_e_k4, s_e_k4, V_i_k4, n_i_k4, s_i_k4, I_e, I_i,\n",
    "                             omega_ee, omega_ei, omega_ie, omega_ii,\n",
    "                             V1, V2, V3, V4, T_max, V_t, K_p,\n",
    "                             g_Ca, V_Ca, g_K, V_K, g_L, V_L,\n",
    "                             phi, ar_e, ad_e, ar_i, ad_i,\n",
    "                             gbar_e, gbar_i, E_ampa, E_gaba, Cm)\n",
    "    V_e_new = V_e + (dt/6.0) * (k1[0] + 2*k2[0] + 2*k3[0] + k4[0])\n",
    "    n_e_new = n_e + (dt/6.0) * (k1[1] + 2*k2[1] + 2*k3[1] + k4[1])\n",
    "    s_e_new = s_e + (dt/6.0) * (k1[2] + 2*k2[2] + 2*k3[2] + k4[2])\n",
    "    V_i_new = V_i + (dt/6.0) * (k1[3] + 2*k2[3] + 2*k3[3] + k4[3])\n",
    "    n_i_new = n_i + (dt/6.0) * (k1[4] + 2*k2[4] + 2*k3[4] + k4[4])\n",
    "    s_i_new = s_i + (dt/6.0) * (k1[5] + 2*k2[5] + 2*k3[5] + k4[5])\n",
    "    return V_e_new, n_e_new, s_e_new, V_i_new, n_i_new, s_i_new\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def integrate_chunk_with_output(\n",
    "    input: torch.Tensor,  \n",
    "    chunk_size: int,\n",
    "    init_V_e: torch.Tensor, init_n_e: torch.Tensor, init_s_e: torch.Tensor,\n",
    "    init_V_i: torch.Tensor, init_n_i: torch.Tensor, init_s_i: torch.Tensor,\n",
    "    dt: float, I: float,\n",
    "    omega_ee: torch.Tensor, omega_ei: torch.Tensor, \n",
    "    omega_ie: torch.Tensor, omega_ii: torch.Tensor,\n",
    "    V1: float, V2: float, V3: float, V4: float,\n",
    "    T_max: float, V_t: float, K_p: float,\n",
    "    g_Ca: float, V_Ca: float, g_K: float, V_K: float, g_L: float, V_L: float,\n",
    "    phi: float, ar_e: float, ad_e: float, ar_i: float, ad_i: float,\n",
    "    gbar_e: float, gbar_i: float, E_ampa: float, E_gaba: float,\n",
    "    Cm: float,\n",
    "    proj_weight: torch.Tensor, proj_bias: torch.Tensor,\n",
    "    out_weight: torch.Tensor, out_bias: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, \n",
    "           Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor], \n",
    "           Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]]:\n",
    "    steps = chunk_size\n",
    "    batch_size = input.size(0)\n",
    "    \n",
    "    # Initialize states:\n",
    "    V_e, n_e, s_e = init_V_e, init_n_e, init_s_e\n",
    "    V_i, n_i, s_i = init_V_i, init_n_i, init_s_i\n",
    "\n",
    "    outputs = []\n",
    "    \n",
    "    V_e_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "    n_e_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "    s_e_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "    V_i_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "    n_i_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "    s_i_list = torch.jit.annotate(List[torch.Tensor], [])\n",
    "\n",
    "    projected_input = 80 * torch.tanh(F.linear(input, proj_weight, proj_bias) + I)\n",
    "    NE = V_e.size(1)\n",
    "    I_e = projected_input[:, :NE]\n",
    "    I_i = projected_input[:, NE:]\n",
    "    \n",
    "    for t in range(steps):       \n",
    "\n",
    "        # Perform one RK4 step with current input:\n",
    "        V_e, n_e, s_e, V_i, n_i, s_i = rk4_step(\n",
    "            V_e, n_e, s_e, V_i, n_i, s_i, I_e, I_i, dt,\n",
    "            omega_ee, omega_ei, omega_ie, omega_ii,\n",
    "            V1, V2, V3, V4, T_max, V_t, K_p,\n",
    "            g_Ca, V_Ca, g_K, V_K, g_L, V_L,\n",
    "            phi, ar_e, ad_e, ar_i, ad_i,\n",
    "            gbar_e, gbar_i, E_ampa, E_gaba, Cm\n",
    "        )\n",
    "        # Compute output for this time step using the output layer:\n",
    "        out = compute_output(s_e, s_i, out_weight, out_bias)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        V_e_list.append(V_e[0].clone())\n",
    "        n_e_list.append(n_e[0].clone())\n",
    "        s_e_list.append(s_e[0].clone())\n",
    "        V_i_list.append(V_i[0].clone())\n",
    "        n_i_list.append(n_i[0].clone())\n",
    "        s_i_list.append(s_i[0].clone())\n",
    "\n",
    "    outputs_tensor = torch.stack(outputs, dim=0)\n",
    "    final_states = (V_e, n_e, s_e, V_i, n_i, s_i)\n",
    "    all_states = (torch.stack(V_e_list, dim=0),\n",
    "                  torch.stack(n_e_list, dim=0),\n",
    "                  torch.stack(s_e_list, dim=0),\n",
    "                  torch.stack(V_i_list, dim=0),\n",
    "                  torch.stack(n_i_list, dim=0),\n",
    "                  torch.stack(s_i_list, dim=0))\n",
    "    return outputs_tensor, final_states, all_states\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Morris-Lecar SNN Model\n",
    "# --------------------------------------------------------------------\n",
    "class MorrisLecarSNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, chunk_size, NE=250, NI=250, dt=0.1,\n",
    "                 Cm=20.0, g_Ca=4.0, g_K=8.0, g_L=2.0, V_Ca=120.0, V_K=-84.0, V_L=-60.0,\n",
    "                 phi=0.067, V1=-1.2, V2=18.0, V3=12.0, V4=17.4, ar_e=3.0, ad_e=0.1,\n",
    "                 ar_i=3.0, ad_i=0.1, T_max=1.0, V_t=2.0, K_p=5.0, gbar_e=1.0, gbar_i=1.0,\n",
    "                 E_ampa=0.0, E_gaba=-75.0, I=0.0):\n",
    "        super(MorrisLecarSNN, self).__init__()\n",
    "        self.NE = NE\n",
    "        self.NI = NI\n",
    "        self.dt = dt\n",
    "        self.hidden_size = NE + NI\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        # Model parameters\n",
    "        self.I = I\n",
    "        self.Cm = Cm\n",
    "        self.g_Ca = g_Ca\n",
    "        self.g_K = g_K\n",
    "        self.g_L = g_L\n",
    "        self.V_Ca = V_Ca\n",
    "        self.V_K = V_K\n",
    "        self.V_L = V_L\n",
    "        self.phi = phi\n",
    "        self.V1 = V1\n",
    "        self.V2 = V2\n",
    "        self.V3 = V3\n",
    "        self.V4 = V4\n",
    "        self.ar_e = ar_e\n",
    "        self.ad_e = ad_e\n",
    "        self.ar_i = ar_i\n",
    "        self.ad_i = ad_i\n",
    "        self.T_max = T_max\n",
    "        self.V_t = V_t\n",
    "        self.K_p = K_p\n",
    "        self.gbar_e = gbar_e\n",
    "        self.gbar_i = gbar_i\n",
    "        self.E_ampa = E_ampa\n",
    "        self.E_gaba = E_gaba\n",
    "\n",
    "        # Input layer\n",
    "        self.input_projection = nn.Linear(input_size, self.hidden_size)\n",
    "        \n",
    "        # Synaptic weights\n",
    "        self.omega_ee_raw = nn.Parameter(torch.randn(NE, NE, device=device))\n",
    "        self.omega_ei_raw = nn.Parameter(torch.randn(NE, NE, device=device))\n",
    "        self.omega_ie_raw = nn.Parameter(torch.randn(NE, NE, device=device))\n",
    "        self.omega_ii_raw = nn.Parameter(torch.randn(NE, NE, device=device))\n",
    "        \n",
    "        # Upper bound\n",
    "        self.upper_bound = 1 / math.sqrt(self.hidden_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "        # State storage (if needed)\n",
    "        self.store_states = False\n",
    "        self._storage = None\n",
    "        self._storage_idx = 0\n",
    "    \n",
    "    # Property to get bounded omega matrices\n",
    "    @property\n",
    "    def omega_ee(self):\n",
    "        return torch.sigmoid(self.omega_ee_raw) * self.upper_bound\n",
    "    \n",
    "    @property\n",
    "    def omega_ei(self):\n",
    "        return torch.sigmoid(self.omega_ei_raw) * self.upper_bound\n",
    "    \n",
    "    @property\n",
    "    def omega_ie(self):\n",
    "        return torch.sigmoid(self.omega_ie_raw) * self.upper_bound\n",
    "    \n",
    "    @property\n",
    "    def omega_ii(self):\n",
    "        return torch.sigmoid(self.omega_ii_raw) * self.upper_bound\n",
    "    \n",
    "    def _init_storage(self, total_steps: int):\n",
    "        device = self.input_projection.weight.device\n",
    "        self._storage = {\n",
    "            'V_e': torch.zeros(total_steps, self.NE, device=device),\n",
    "            'n_e': torch.zeros(total_steps, self.NE, device=device),\n",
    "            's_e': torch.zeros(total_steps, self.NE, device=device),\n",
    "            'V_i': torch.zeros(total_steps, self.NI, device=device),\n",
    "            'n_i': torch.zeros(total_steps, self.NI, device=device),\n",
    "            's_i': torch.zeros(total_steps, self.NI, device=device)\n",
    "        }\n",
    "        self._storage_idx = 0\n",
    "\n",
    "    def enable_storage(self, total_steps: int):\n",
    "        self.store_states = True\n",
    "        self._init_storage(total_steps)\n",
    "\n",
    "    def disable_storage(self):\n",
    "        self.store_states = False\n",
    "        self._storage = None\n",
    "        self._storage_idx = 0\n",
    "\n",
    "    def get_storage(self):\n",
    "        return self._storage\n",
    "\n",
    "    def _init_states(self, batch_size: int):\n",
    "        device = self.input_projection.weight.device\n",
    "        V_e = 30 * torch.rand((batch_size, self.NE), device=device)\n",
    "        n_e = torch.rand((batch_size, self.NE), device=device)\n",
    "        s_e = torch.zeros((batch_size, self.NE), device=device)\n",
    "        V_i = -50 + 30 * torch.rand((batch_size, self.NI), device=device)\n",
    "        n_i = torch.rand((batch_size, self.NI), device=device)\n",
    "        s_i = torch.zeros((batch_size, self.NI), device=device)\n",
    "        return (V_e, n_e, s_e, V_i, n_i, s_i)\n",
    "\n",
    "    def forward(self, input, states=None):\n",
    "        \"\"\"\n",
    "        x_sequence: [batch_size, seq_len, input_size]\n",
    "        For each time step, we require the output.\n",
    "        We process the sequence in chunks using our scripted integration function.\n",
    "        \"\"\"\n",
    "        batch_size, _ = input.shape\n",
    "        outputs_list = []\n",
    "\n",
    "        if states is None:\n",
    "            states = self._init_states(batch_size)\n",
    "        \n",
    "        # We need to get the projection and output layer parameters.\n",
    "        proj_weight = self.input_projection.weight\n",
    "        proj_bias = self.input_projection.bias\n",
    "        out_weight = self.output_layer.weight\n",
    "        out_bias = self.output_layer.bias\n",
    "\n",
    "        # Call the scripted integration function that returns outputs for each step in the chunk.\n",
    "        chunk_outputs, states, all_states = integrate_chunk_with_output(\n",
    "            input, self.chunk_size, states[0], states[1], states[2],\n",
    "            states[3], states[4], states[5],\n",
    "            self.dt, self.I,\n",
    "            self.omega_ee, self.omega_ei, self.omega_ie, self.omega_ii,\n",
    "            self.V1, self.V2, self.V3, self.V4,\n",
    "            self.T_max, self.V_t, self.K_p,\n",
    "            self.g_Ca, self.V_Ca, self.g_K, self.V_K, self.g_L, self.V_L,\n",
    "            self.phi, self.ar_e, self.ad_e, self.ar_i, self.ad_i,\n",
    "            self.gbar_e, self.gbar_i, self.E_ampa, self.E_gaba,\n",
    "            self.Cm,\n",
    "            proj_weight, proj_bias,\n",
    "            out_weight, out_bias\n",
    "        )\n",
    "       \n",
    "        chunk_outputs = chunk_outputs.transpose(0, 1)\n",
    "        outputs_list.append(chunk_outputs)\n",
    "        if self.store_states:\n",
    "            steps = self.chunk_size\n",
    "            with torch.no_grad():\n",
    "                self._storage['V_e'][self._storage_idx:self._storage_idx + steps] = all_states[0]\n",
    "                self._storage['n_e'][self._storage_idx:self._storage_idx + steps] = all_states[1]\n",
    "                self._storage['s_e'][self._storage_idx:self._storage_idx + steps] = all_states[2]\n",
    "                self._storage['V_i'][self._storage_idx:self._storage_idx + steps] = all_states[3]\n",
    "                self._storage['n_i'][self._storage_idx:self._storage_idx + steps] = all_states[4]\n",
    "                self._storage['s_i'][self._storage_idx:self._storage_idx + steps] = all_states[5]\n",
    "                self._storage_idx += steps\n",
    "        outputs = torch.cat(outputs_list, dim=1)\n",
    "        return outputs, states\n",
    "\n",
    "    def warmup(self, input, states=None):\n",
    "        \"\"\"\n",
    "        x_sequence: [batch_size, seq_len, input_size]\n",
    "        For each time step, we require the output.\n",
    "        We process the sequence in chunks using our scripted integration function.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            batch_size, _ = input.shape\n",
    "            outputs_list = []\n",
    "    \n",
    "            if states is None:\n",
    "                states = self._init_states(batch_size)\n",
    "            \n",
    "            # We need to get the projection and output layer parameters.\n",
    "            proj_weight = self.input_projection.weight\n",
    "            proj_bias = self.input_projection.bias\n",
    "            out_weight = self.output_layer.weight\n",
    "            out_bias = self.output_layer.bias\n",
    "\n",
    "            # Call the scripted integration function that returns outputs for each step in the chunk.\n",
    "            _, states, _ = integrate_chunk_with_output(\n",
    "                input, self.chunk_size, states[0], states[1], states[2],\n",
    "                states[3], states[4], states[5],\n",
    "                self.dt, self.I,\n",
    "                self.omega_ee, self.omega_ei, self.omega_ie, self.omega_ii,\n",
    "                self.V1, self.V2, self.V3, self.V4,\n",
    "                self.T_max, self.V_t, self.K_p,\n",
    "                self.g_Ca, self.V_Ca, self.g_K, self.V_K, self.g_L, self.V_L,\n",
    "                self.phi, self.ar_e, self.ad_e, self.ar_i, self.ad_i,\n",
    "                self.gbar_e, self.gbar_i, self.E_ampa, self.E_gaba,\n",
    "                self.Cm,\n",
    "                proj_weight, proj_bias,\n",
    "                out_weight, out_bias\n",
    "            )\n",
    "           \n",
    "        return states\n",
    "\n",
    "\n",
    "    def plot_full_state(self, num_neurons=5, neuron_offset=2.0, figure_name=\"\"):\n",
    "        if not self.store_states or self._storage is None:\n",
    "            print(\"Storage not enabled or no data stored!\")\n",
    "            return\n",
    "        \n",
    "        store = {k: v.cpu().numpy() for k, v in self._storage.items()}\n",
    "        time_steps = store['V_e'].shape[0]\n",
    "        time = np.arange(0, time_steps) * self.dt\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 12))\n",
    "        plt.suptitle(\"Neuronal State Dynamics (T=100s)\", fontsize=16)\n",
    "        gs = fig.add_gridspec(3, 2)\n",
    "        axs = {\n",
    "            'V_e': fig.add_subplot(gs[0, 0]),\n",
    "            'V_i': fig.add_subplot(gs[0, 1]),\n",
    "            'n_e': fig.add_subplot(gs[1, 0]),\n",
    "            'n_i': fig.add_subplot(gs[1, 1]),\n",
    "            's_e': fig.add_subplot(gs[2, 0]),\n",
    "            's_i': fig.add_subplot(gs[2, 1])\n",
    "        }\n",
    "\n",
    "        rand_e = np.random.choice(self.NE, num_neurons, replace=False)\n",
    "        rand_i = np.random.choice(self.NI, num_neurons, replace=False)\n",
    "\n",
    "        for idx, n in enumerate(rand_e):\n",
    "            offset = idx * neuron_offset\n",
    "            axs['V_e'].plot(time, (store['V_e'][:, n]) / 150 + offset, label=f'Neuron {n}')\n",
    "            axs['n_e'].plot(time, store['n_e'][:, n] + offset)\n",
    "            axs['s_e'].plot(time, store['s_e'][:, n] + offset)\n",
    "\n",
    "        for idx, n in enumerate(rand_i):\n",
    "            offset = idx * neuron_offset\n",
    "            axs['V_i'].plot(time, (store['V_i'][:, n]) / 150 + offset, label=f'Neuron {n}')\n",
    "            axs['n_i'].plot(time, store['n_i'][:, n] + offset)\n",
    "            axs['s_i'].plot(time, store['s_i'][:, n] + offset)\n",
    "\n",
    "        titles = {\n",
    "            'V_e': \"Excitatory Membrane Potentials\",\n",
    "            'V_i': \"Inhibitory Membrane Potentials\",\n",
    "            'n_e': \"Excitatory Gating Variables\",\n",
    "            'n_i': \"Inhibitory Gating Variables\",\n",
    "            's_e': \"Excitatory Synaptic Variables\",\n",
    "            's_i': \"Inhibitory Synaptic Variables\"\n",
    "        }\n",
    "        for key, ax in axs.items():\n",
    "            ax.set_title(titles[key])\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            if key in ['V_e', 'V_i']:\n",
    "                ax.legend()\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        if figure_name:\n",
    "            plt.savefig(figure_name, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17264cd6",
   "metadata": {},
   "source": [
    "## Initialize the model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf091647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model state saved to MNIST-initial.pth\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "\n",
    "chunk_size = 100\n",
    "epochs = 5\n",
    "states = None\n",
    "\n",
    "NE = 500\n",
    "NI = 500\n",
    "\n",
    "model = MorrisLecarSNN(input_size=28*28, output_size=10, chunk_size=chunk_size, NE=NE, NI=NI, dt=dt).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "initial_state_path = 'MNIST-initial.pth'\n",
    "final_state_path = 'MNIST-final.pth'\n",
    "\n",
    "torch.save(model.state_dict(), initial_state_path)\n",
    "print(f\"Initial model state saved to {initial_state_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7cd80",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Progress: 4.00%, BatchLoss: 203.4523, BatchAccuracy: 0.6162, TotalAccuracy: 0.0246\n",
      "Epoch: 1/5, Progress: 8.00%, BatchLoss: 104.1989, BatchAccuracy: 0.8342, TotalAccuracy: 0.0580\n",
      "Epoch: 1/5, Progress: 12.00%, BatchLoss: 68.5518, BatchAccuracy: 0.8812, TotalAccuracy: 0.0933\n",
      "Epoch: 1/5, Progress: 16.00%, BatchLoss: 53.1463, BatchAccuracy: 0.9008, TotalAccuracy: 0.1293\n",
      "Epoch: 1/5, Progress: 20.00%, BatchLoss: 45.9371, BatchAccuracy: 0.9004, TotalAccuracy: 0.1653\n",
      "Epoch: 1/5, Progress: 24.00%, BatchLoss: 40.7101, BatchAccuracy: 0.9154, TotalAccuracy: 0.2019\n",
      "Epoch: 1/5, Progress: 28.00%, BatchLoss: 39.5597, BatchAccuracy: 0.9179, TotalAccuracy: 0.2387\n",
      "Epoch: 1/5, Progress: 32.00%, BatchLoss: 37.1136, BatchAccuracy: 0.9246, TotalAccuracy: 0.2756\n",
      "Epoch: 1/5, Progress: 36.00%, BatchLoss: 36.7255, BatchAccuracy: 0.9183, TotalAccuracy: 0.3124\n",
      "Epoch: 1/5, Progress: 40.00%, BatchLoss: 33.9050, BatchAccuracy: 0.9237, TotalAccuracy: 0.3493\n",
      "Epoch: 1/5, Progress: 44.00%, BatchLoss: 31.9045, BatchAccuracy: 0.9371, TotalAccuracy: 0.3868\n",
      "Epoch: 1/5, Progress: 48.00%, BatchLoss: 30.5597, BatchAccuracy: 0.9321, TotalAccuracy: 0.4241\n",
      "Epoch: 1/5, Progress: 52.00%, BatchLoss: 28.5495, BatchAccuracy: 0.9429, TotalAccuracy: 0.4618\n",
      "Epoch: 1/5, Progress: 56.00%, BatchLoss: 26.6382, BatchAccuracy: 0.9387, TotalAccuracy: 0.4994\n",
      "Epoch: 1/5, Progress: 60.00%, BatchLoss: 25.3323, BatchAccuracy: 0.9442, TotalAccuracy: 0.5371\n",
      "Epoch: 1/5, Progress: 64.00%, BatchLoss: 28.2062, BatchAccuracy: 0.9392, TotalAccuracy: 0.5747\n",
      "Epoch: 1/5, Progress: 68.00%, BatchLoss: 24.5634, BatchAccuracy: 0.9471, TotalAccuracy: 0.6126\n",
      "Epoch: 1/5, Progress: 72.00%, BatchLoss: 25.2315, BatchAccuracy: 0.9450, TotalAccuracy: 0.6504\n",
      "Epoch: 1/5, Progress: 76.00%, BatchLoss: 23.6008, BatchAccuracy: 0.9479, TotalAccuracy: 0.6883\n",
      "Epoch: 1/5, Progress: 80.00%, BatchLoss: 24.9214, BatchAccuracy: 0.9454, TotalAccuracy: 0.7261\n",
      "Epoch: 1/5, Progress: 84.00%, BatchLoss: 20.8254, BatchAccuracy: 0.9600, TotalAccuracy: 0.7645\n",
      "Epoch: 1/5, Progress: 88.00%, BatchLoss: 19.8831, BatchAccuracy: 0.9587, TotalAccuracy: 0.8028\n",
      "Epoch: 1/5, Progress: 92.00%, BatchLoss: 21.8264, BatchAccuracy: 0.9521, TotalAccuracy: 0.8409\n",
      "Epoch: 1/5, Progress: 96.00%, BatchLoss: 20.5130, BatchAccuracy: 0.9579, TotalAccuracy: 0.8792\n",
      "Epoch: 1/5, Progress: 100.00%, BatchLoss: 20.4954, BatchAccuracy: 0.9587, TotalAccuracy: 0.9176\n",
      "Epoch: 1, TotalLoss: 1036.3513, Accuracy: 0.9176\n",
      "Epoch: 2/5, Progress: 4.00%, BatchLoss: 20.3055, BatchAccuracy: 0.9558, TotalAccuracy: 0.0382\n",
      "Epoch: 2/5, Progress: 8.00%, BatchLoss: 18.8301, BatchAccuracy: 0.9608, TotalAccuracy: 0.0767\n",
      "Epoch: 2/5, Progress: 12.00%, BatchLoss: 16.0926, BatchAccuracy: 0.9633, TotalAccuracy: 0.1152\n",
      "Epoch: 2/5, Progress: 16.00%, BatchLoss: 14.4296, BatchAccuracy: 0.9742, TotalAccuracy: 0.1542\n",
      "Epoch: 2/5, Progress: 20.00%, BatchLoss: 15.9576, BatchAccuracy: 0.9696, TotalAccuracy: 0.1930\n",
      "Epoch: 2/5, Progress: 24.00%, BatchLoss: 22.7636, BatchAccuracy: 0.9487, TotalAccuracy: 0.2309\n",
      "Epoch: 2/5, Progress: 28.00%, BatchLoss: 17.3803, BatchAccuracy: 0.9629, TotalAccuracy: 0.2694\n",
      "Epoch: 2/5, Progress: 32.00%, BatchLoss: 17.0647, BatchAccuracy: 0.9642, TotalAccuracy: 0.3080\n",
      "Epoch: 2/5, Progress: 36.00%, BatchLoss: 17.1005, BatchAccuracy: 0.9625, TotalAccuracy: 0.3465\n",
      "Epoch: 2/5, Progress: 40.00%, BatchLoss: 15.4075, BatchAccuracy: 0.9683, TotalAccuracy: 0.3852\n",
      "Epoch: 2/5, Progress: 44.00%, BatchLoss: 16.8132, BatchAccuracy: 0.9625, TotalAccuracy: 0.4237\n",
      "Epoch: 2/5, Progress: 48.00%, BatchLoss: 15.9426, BatchAccuracy: 0.9658, TotalAccuracy: 0.4623\n",
      "Epoch: 2/5, Progress: 52.00%, BatchLoss: 16.0038, BatchAccuracy: 0.9692, TotalAccuracy: 0.5011\n",
      "Epoch: 2/5, Progress: 56.00%, BatchLoss: 16.6360, BatchAccuracy: 0.9654, TotalAccuracy: 0.5397\n",
      "Epoch: 2/5, Progress: 60.00%, BatchLoss: 13.8241, BatchAccuracy: 0.9696, TotalAccuracy: 0.5785\n",
      "Epoch: 2/5, Progress: 64.00%, BatchLoss: 14.0756, BatchAccuracy: 0.9717, TotalAccuracy: 0.6174\n",
      "Epoch: 2/5, Progress: 68.00%, BatchLoss: 15.6021, BatchAccuracy: 0.9683, TotalAccuracy: 0.6561\n",
      "Epoch: 2/5, Progress: 72.00%, BatchLoss: 15.1479, BatchAccuracy: 0.9679, TotalAccuracy: 0.6948\n",
      "Epoch: 2/5, Progress: 76.00%, BatchLoss: 14.0380, BatchAccuracy: 0.9696, TotalAccuracy: 0.7336\n",
      "Epoch: 2/5, Progress: 80.00%, BatchLoss: 13.1398, BatchAccuracy: 0.9696, TotalAccuracy: 0.7724\n",
      "Epoch: 2/5, Progress: 84.00%, BatchLoss: 14.9260, BatchAccuracy: 0.9688, TotalAccuracy: 0.8112\n",
      "Epoch: 2/5, Progress: 88.00%, BatchLoss: 11.5417, BatchAccuracy: 0.9788, TotalAccuracy: 0.8503\n",
      "Epoch: 2/5, Progress: 92.00%, BatchLoss: 13.3639, BatchAccuracy: 0.9729, TotalAccuracy: 0.8892\n",
      "Epoch: 2/5, Progress: 96.00%, BatchLoss: 13.2751, BatchAccuracy: 0.9688, TotalAccuracy: 0.9280\n",
      "Epoch: 2/5, Progress: 100.00%, BatchLoss: 14.0858, BatchAccuracy: 0.9658, TotalAccuracy: 0.9666\n",
      "Epoch: 2, TotalLoss: 393.7475, Accuracy: 0.9666\n",
      "Epoch: 3/5, Progress: 4.00%, BatchLoss: 9.9794, BatchAccuracy: 0.9796, TotalAccuracy: 0.0392\n",
      "Epoch: 3/5, Progress: 8.00%, BatchLoss: 10.4921, BatchAccuracy: 0.9796, TotalAccuracy: 0.0784\n",
      "Epoch: 3/5, Progress: 12.00%, BatchLoss: 10.1639, BatchAccuracy: 0.9829, TotalAccuracy: 0.1177\n",
      "Epoch: 3/5, Progress: 16.00%, BatchLoss: 10.2054, BatchAccuracy: 0.9821, TotalAccuracy: 0.1570\n",
      "Epoch: 3/5, Progress: 20.00%, BatchLoss: 9.6956, BatchAccuracy: 0.9788, TotalAccuracy: 0.1961\n",
      "Epoch: 3/5, Progress: 24.00%, BatchLoss: 12.0012, BatchAccuracy: 0.9788, TotalAccuracy: 0.2353\n",
      "Epoch: 3/5, Progress: 28.00%, BatchLoss: 10.3199, BatchAccuracy: 0.9788, TotalAccuracy: 0.2744\n",
      "Epoch: 3/5, Progress: 32.00%, BatchLoss: 10.6320, BatchAccuracy: 0.9783, TotalAccuracy: 0.3135\n",
      "Epoch: 3/5, Progress: 36.00%, BatchLoss: 11.3665, BatchAccuracy: 0.9746, TotalAccuracy: 0.3525\n",
      "Epoch: 3/5, Progress: 40.00%, BatchLoss: 8.9487, BatchAccuracy: 0.9829, TotalAccuracy: 0.3918\n",
      "Epoch: 3/5, Progress: 44.00%, BatchLoss: 11.3291, BatchAccuracy: 0.9767, TotalAccuracy: 0.4309\n",
      "Epoch: 3/5, Progress: 48.00%, BatchLoss: 9.8537, BatchAccuracy: 0.9792, TotalAccuracy: 0.4701\n",
      "Epoch: 3/5, Progress: 52.00%, BatchLoss: 10.0469, BatchAccuracy: 0.9817, TotalAccuracy: 0.5093\n",
      "Epoch: 3/5, Progress: 56.00%, BatchLoss: 9.9563, BatchAccuracy: 0.9771, TotalAccuracy: 0.5484\n",
      "Epoch: 3/5, Progress: 60.00%, BatchLoss: 9.8619, BatchAccuracy: 0.9804, TotalAccuracy: 0.5877\n",
      "Epoch: 3/5, Progress: 64.00%, BatchLoss: 9.8258, BatchAccuracy: 0.9812, TotalAccuracy: 0.6269\n",
      "Epoch: 3/5, Progress: 68.00%, BatchLoss: 13.3236, BatchAccuracy: 0.9729, TotalAccuracy: 0.6658\n",
      "Epoch: 3/5, Progress: 72.00%, BatchLoss: 10.8545, BatchAccuracy: 0.9800, TotalAccuracy: 0.7050\n",
      "Epoch: 3/5, Progress: 76.00%, BatchLoss: 11.6619, BatchAccuracy: 0.9750, TotalAccuracy: 0.7440\n",
      "Epoch: 3/5, Progress: 80.00%, BatchLoss: 10.0690, BatchAccuracy: 0.9792, TotalAccuracy: 0.7832\n",
      "Epoch: 3/5, Progress: 84.00%, BatchLoss: 10.8947, BatchAccuracy: 0.9796, TotalAccuracy: 0.8224\n",
      "Epoch: 3/5, Progress: 88.00%, BatchLoss: 10.6961, BatchAccuracy: 0.9825, TotalAccuracy: 0.8617\n",
      "Epoch: 3/5, Progress: 92.00%, BatchLoss: 9.6223, BatchAccuracy: 0.9800, TotalAccuracy: 0.9009\n",
      "Epoch: 3/5, Progress: 96.00%, BatchLoss: 9.8480, BatchAccuracy: 0.9796, TotalAccuracy: 0.9401\n",
      "Epoch: 3/5, Progress: 100.00%, BatchLoss: 8.6691, BatchAccuracy: 0.9854, TotalAccuracy: 0.9795\n",
      "Epoch: 3, TotalLoss: 260.3178, Accuracy: 0.9795\n",
      "Epoch: 4/5, Progress: 4.00%, BatchLoss: 7.8065, BatchAccuracy: 0.9867, TotalAccuracy: 0.0395\n",
      "Epoch: 4/5, Progress: 8.00%, BatchLoss: 8.0365, BatchAccuracy: 0.9871, TotalAccuracy: 0.0790\n",
      "Epoch: 4/5, Progress: 12.00%, BatchLoss: 7.1108, BatchAccuracy: 0.9871, TotalAccuracy: 0.1184\n",
      "Epoch: 4/5, Progress: 16.00%, BatchLoss: 7.1105, BatchAccuracy: 0.9842, TotalAccuracy: 0.1578\n",
      "Epoch: 4/5, Progress: 20.00%, BatchLoss: 7.0177, BatchAccuracy: 0.9892, TotalAccuracy: 0.1974\n",
      "Epoch: 4/5, Progress: 24.00%, BatchLoss: 7.5561, BatchAccuracy: 0.9829, TotalAccuracy: 0.2367\n",
      "Epoch: 4/5, Progress: 28.00%, BatchLoss: 6.5735, BatchAccuracy: 0.9883, TotalAccuracy: 0.2762\n",
      "Epoch: 4/5, Progress: 32.00%, BatchLoss: 6.8977, BatchAccuracy: 0.9850, TotalAccuracy: 0.3156\n",
      "Epoch: 4/5, Progress: 36.00%, BatchLoss: 7.1985, BatchAccuracy: 0.9858, TotalAccuracy: 0.3550\n",
      "Epoch: 4/5, Progress: 40.00%, BatchLoss: 7.3435, BatchAccuracy: 0.9875, TotalAccuracy: 0.3946\n",
      "Epoch: 4/5, Progress: 44.00%, BatchLoss: 7.1465, BatchAccuracy: 0.9846, TotalAccuracy: 0.4339\n",
      "Epoch: 4/5, Progress: 48.00%, BatchLoss: 7.4561, BatchAccuracy: 0.9850, TotalAccuracy: 0.4733\n",
      "Epoch: 4/5, Progress: 52.00%, BatchLoss: 7.7059, BatchAccuracy: 0.9829, TotalAccuracy: 0.5127\n",
      "Epoch: 4/5, Progress: 56.00%, BatchLoss: 8.6255, BatchAccuracy: 0.9842, TotalAccuracy: 0.5520\n",
      "Epoch: 4/5, Progress: 60.00%, BatchLoss: 8.0023, BatchAccuracy: 0.9825, TotalAccuracy: 0.5913\n",
      "Epoch: 4/5, Progress: 64.00%, BatchLoss: 7.7298, BatchAccuracy: 0.9825, TotalAccuracy: 0.6306\n",
      "Epoch: 4/5, Progress: 68.00%, BatchLoss: 8.4886, BatchAccuracy: 0.9833, TotalAccuracy: 0.6700\n",
      "Epoch: 4/5, Progress: 72.00%, BatchLoss: 7.6398, BatchAccuracy: 0.9854, TotalAccuracy: 0.7094\n",
      "Epoch: 4/5, Progress: 76.00%, BatchLoss: 9.1505, BatchAccuracy: 0.9812, TotalAccuracy: 0.7486\n",
      "Epoch: 4/5, Progress: 80.00%, BatchLoss: 8.2890, BatchAccuracy: 0.9854, TotalAccuracy: 0.7880\n",
      "Epoch: 4/5, Progress: 84.00%, BatchLoss: 8.3958, BatchAccuracy: 0.9817, TotalAccuracy: 0.8273\n",
      "Epoch: 4/5, Progress: 88.00%, BatchLoss: 7.4163, BatchAccuracy: 0.9833, TotalAccuracy: 0.8666\n",
      "Epoch: 4/5, Progress: 92.00%, BatchLoss: 7.7434, BatchAccuracy: 0.9858, TotalAccuracy: 0.9061\n",
      "Epoch: 4/5, Progress: 96.00%, BatchLoss: 6.7145, BatchAccuracy: 0.9858, TotalAccuracy: 0.9455\n",
      "Epoch: 4/5, Progress: 100.00%, BatchLoss: 7.4648, BatchAccuracy: 0.9850, TotalAccuracy: 0.9849\n",
      "Epoch: 4, TotalLoss: 190.6201, Accuracy: 0.9849\n",
      "Epoch: 5/5, Progress: 4.00%, BatchLoss: 5.6986, BatchAccuracy: 0.9900, TotalAccuracy: 0.0396\n",
      "Epoch: 5/5, Progress: 8.00%, BatchLoss: 4.3129, BatchAccuracy: 0.9925, TotalAccuracy: 0.0793\n",
      "Epoch: 5/5, Progress: 12.00%, BatchLoss: 5.8282, BatchAccuracy: 0.9908, TotalAccuracy: 0.1189\n",
      "Epoch: 5/5, Progress: 16.00%, BatchLoss: 4.9482, BatchAccuracy: 0.9921, TotalAccuracy: 0.1586\n",
      "Epoch: 5/5, Progress: 20.00%, BatchLoss: 6.0013, BatchAccuracy: 0.9904, TotalAccuracy: 0.1982\n",
      "Epoch: 5/5, Progress: 24.00%, BatchLoss: 5.6235, BatchAccuracy: 0.9908, TotalAccuracy: 0.2379\n",
      "Epoch: 5/5, Progress: 28.00%, BatchLoss: 5.2935, BatchAccuracy: 0.9912, TotalAccuracy: 0.2775\n",
      "Epoch: 5/5, Progress: 32.00%, BatchLoss: 5.0101, BatchAccuracy: 0.9900, TotalAccuracy: 0.3171\n",
      "Epoch: 5/5, Progress: 36.00%, BatchLoss: 5.0585, BatchAccuracy: 0.9917, TotalAccuracy: 0.3568\n",
      "Epoch: 5/5, Progress: 40.00%, BatchLoss: 4.4386, BatchAccuracy: 0.9925, TotalAccuracy: 0.3965\n",
      "Epoch: 5/5, Progress: 44.00%, BatchLoss: 4.3945, BatchAccuracy: 0.9921, TotalAccuracy: 0.4362\n",
      "Epoch: 5/5, Progress: 48.00%, BatchLoss: 5.8693, BatchAccuracy: 0.9883, TotalAccuracy: 0.4757\n",
      "Epoch: 5/5, Progress: 52.00%, BatchLoss: 5.1520, BatchAccuracy: 0.9879, TotalAccuracy: 0.5152\n",
      "Epoch: 5/5, Progress: 56.00%, BatchLoss: 6.5882, BatchAccuracy: 0.9850, TotalAccuracy: 0.5546\n",
      "Epoch: 5/5, Progress: 60.00%, BatchLoss: 6.0097, BatchAccuracy: 0.9867, TotalAccuracy: 0.5941\n",
      "Epoch: 5/5, Progress: 64.00%, BatchLoss: 7.0148, BatchAccuracy: 0.9850, TotalAccuracy: 0.6335\n",
      "Epoch: 5/5, Progress: 68.00%, BatchLoss: 5.7403, BatchAccuracy: 0.9900, TotalAccuracy: 0.6731\n",
      "Epoch: 5/5, Progress: 72.00%, BatchLoss: 5.6937, BatchAccuracy: 0.9879, TotalAccuracy: 0.7126\n",
      "Epoch: 5/5, Progress: 76.00%, BatchLoss: 4.6603, BatchAccuracy: 0.9933, TotalAccuracy: 0.7523\n",
      "Epoch: 5/5, Progress: 80.00%, BatchLoss: 6.0436, BatchAccuracy: 0.9871, TotalAccuracy: 0.7918\n",
      "Epoch: 5/5, Progress: 84.00%, BatchLoss: 5.3558, BatchAccuracy: 0.9904, TotalAccuracy: 0.8314\n",
      "Epoch: 5/5, Progress: 88.00%, BatchLoss: 5.9474, BatchAccuracy: 0.9875, TotalAccuracy: 0.8709\n",
      "Epoch: 5/5, Progress: 92.00%, BatchLoss: 7.3288, BatchAccuracy: 0.9858, TotalAccuracy: 0.9104\n",
      "Epoch: 5/5, Progress: 96.00%, BatchLoss: 5.7919, BatchAccuracy: 0.9888, TotalAccuracy: 0.9499\n",
      "Epoch: 5/5, Progress: 100.00%, BatchLoss: 6.4406, BatchAccuracy: 0.9871, TotalAccuracy: 0.9894\n",
      "Epoch: 5, TotalLoss: 140.2442, Accuracy: 0.9894\n",
      "Model and optimizer state saved successfully!\n",
      "CPU times: user 54min 41s, sys: 7.55 s, total: 54min 49s\n",
      "Wall time: 45min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "\n",
    "progress_interval = 0.04\n",
    "\n",
    "warmup_duration = 200\n",
    "epoch_has_nan = False\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    total_right = 0\n",
    "    batch_right = 0\n",
    "    total_loss = 0\n",
    "    batch_loss = 0\n",
    "\n",
    "    num_batches = len(train_dataloader)\n",
    "    progress_step = int(progress_interval * num_batches) \n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        input_seq = images.view(batch_size, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        states = None \n",
    "        outputs_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            states = model.warmup(torch.zeros(batch_size, 28*28).to(device), states)        \n",
    "\n",
    "        # Process the sequence in TBPTT chunks\n",
    "        for start in range(0, nt, chunk_size):\n",
    "            \n",
    "            chunk_outputs, states = model(input_seq, states)\n",
    "            avg_outputs = torch.mean(chunk_outputs, dim=1)\n",
    "            loss = criterion(avg_outputs, labels.long())\n",
    "\n",
    "            loss.backward()\n",
    "            batch_loss += loss.detach().item()\n",
    "            total_loss += loss.detach().item()\n",
    "            outputs_list.append(chunk_outputs.detach())\n",
    "\n",
    "            if states is not None:\n",
    "                states = tuple(s.detach() for s in states)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs = torch.cat(outputs_list, dim=1)\n",
    "        avg_outputs = torch.mean(outputs, dim=1) \n",
    "        predictions = torch.argmax(avg_outputs, dim=1)\n",
    "\n",
    "        correct_predictions = (predictions == labels).sum().item()\n",
    "\n",
    "        batch_right += correct_predictions\n",
    "        total_right += correct_predictions\n",
    "\n",
    "        if (batch_idx + 1) % progress_step == 0 or (batch_idx + 1) == num_batches:\n",
    "            print(f\"Epoch: {epoch+1}/{epochs}, \"\n",
    "                  f\"Progress: {100 * (batch_idx + 1) / num_batches:.2f}%, \"\n",
    "                  f\"BatchLoss: {batch_loss:.4f}, \"\n",
    "                  f\"BatchAccuracy: {batch_right / (batch_size * num_batches * progress_interval):.4f}, \"\n",
    "                  f\"TotalAccuracy: {total_right / len(train_dataloader.dataset):.4f}\")\n",
    "            batch_loss = 0\n",
    "            batch_right = 0\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, TotalLoss: {total_loss:.4f}, \"\n",
    "        f\"Accuracy: {total_right / len(train_dataloader.dataset):.4f}\")\n",
    "\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, final_state_path)\n",
    "print(\"Model and optimizer state saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28da7bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(final_state_path, map_location=device)\n",
    "\n",
    "model = MorrisLecarSNN(input_size=28*28, output_size=10, chunk_size=chunk_size, NE=500, NI=500, dt=dt).to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9a5cd",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63bc7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0014, Test Accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "num_samples = 0\n",
    "warmup_duration = 200\n",
    "model.disable_storage()\n",
    "model.enable_storage(total_steps=nt)\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        input = images.view(batch_size, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        states = None  \n",
    "        outputs_list = []\n",
    "        model._storage_idx = 0 \n",
    "\n",
    "        with torch.no_grad():\n",
    "            states = model.warmup(torch.zeros(batch_size, 28*28).to(device), states)   \n",
    "\n",
    "        \n",
    "        for start in range(0, nt, chunk_size):\n",
    "            chunk_outputs, states = model(input, states)\n",
    "            avg_outputs = torch.mean(chunk_outputs, dim=1)  \n",
    "            total_loss = criterion(avg_outputs, labels.long()).item()\n",
    "\n",
    "            outputs_list.append(chunk_outputs)\n",
    "\n",
    "            if states is not None:\n",
    "                states = tuple(s.detach() for s in states)\n",
    "\n",
    "        outputs = torch.cat(outputs_list, dim=1)\n",
    "        avg_outputs = torch.mean(outputs, dim=1)  \n",
    "        predictions = torch.argmax(avg_outputs, dim=1)\n",
    "\n",
    "        # Compute accuracy\n",
    "        total_correct += (predictions == labels).sum().item()\n",
    "        num_samples += labels.size(0)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "\n",
    "# Compute final metrics\n",
    "avg_loss = total_loss / len(test_dataloader)\n",
    "accuracy = total_correct / num_samples\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "data = model.get_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36daada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 975    0    1    1    0    1    0    1    1    0]\n",
      " [   0 1120    3    2    0    1    4    1    3    1]\n",
      " [   5    0 1009    1    1    0    2    7    6    1]\n",
      " [   0    0    0  988    0    8    0    6    3    5]\n",
      " [   3    0    1    1  931    0    5    1    2   38]\n",
      " [   3    0    0    3    1  872    4    1    3    5]\n",
      " [   7    3    1    1    1    4  938    1    2    0]\n",
      " [   1    5    6    1    0    0    0 1005    2    8]\n",
      " [   8    0    1    3    4    4    3    3  944    4]\n",
      " [   3    2    0    5    3    2    0    2    0  992]]\n",
      "\n",
      "Overall Test Accuracy (from Confusion Matrix): 0.9774\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.99      0.95      0.97       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.97       974\n",
      "           9       0.94      0.98      0.96      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optional: Calculate overall accuracy from the confusion matrix\n",
    "overall_accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "print(f\"\\nOverall Test Accuracy (from Confusion Matrix): {overall_accuracy:.4f}\")\n",
    "class_names = [str(i) for i in range(10)] # Assuming 10 classes (0-9)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6afa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
